#!/usr/bin/env python3
"""Convert ALL remaining json.dumps returns to TOON compression pattern"""

import re
from pathlib import Path
from typing import Dict, List, Tuple

def convert_file_toon(filepath: Path) -> Tuple[int, List[str]]:
    """Convert all json.dumps returns in a file to TOON pattern."""

    content = filepath.read_text()
    conversions = []

    # Generic pattern: find all json.dumps returns and convert them
    # Pattern: return [TextContent(type="text", text=json.dumps(VAR, indent=2))]
    pattern = r'( *)return \[TextContent\(type="text", text=json\.dumps\((\w+)(?:, indent=\d+)?\)\)\]'

    def replace_return(match):
        indent = match.group(1)
        var_name = match.group(2)

        # Determine schema name from variable name
        if var_name == "response_data":
            schema = "operation_response"
        elif var_name == "response":
            schema = "operation_response"
        elif var_name == "error_response":
            schema = "operation_error"
        else:
            schema = f"{var_name}_result"

        # Build replacement
        replacement = f'''{indent}result = StructuredResult.success(
{indent}    data={var_name},
{indent}    metadata={{"operation": "handler", "schema": "{schema}"}}
{indent})
{indent}return [result.as_optimized_content(schema_name="{schema}")]'''

        # Special handling for error_response
        if var_name == "error_response":
            replacement = f'''{indent}result = StructuredResult.error(
{indent}    details={var_name},
{indent}    metadata={{"operation": "handler", "schema": "{schema}"}}
{indent})
{indent}return [result.as_optimized_content(schema_name="{schema}")]'''

        return replacement

    # Apply replacements
    original = content
    content = re.sub(pattern, replace_return, content)

    if content != original:
        count = len(re.findall(pattern, original))
        conversions.append(f"Converted {count} handlers in {filepath.name}")

    # Write back
    filepath.write_text(content)

    return len(re.findall(pattern, original)), conversions

def main():
    """Main conversion orchestrator."""

    files_to_convert = [
        'src/athena/mcp/handlers_system.py',
        'src/athena/mcp/handlers_metacognition.py',
        'src/athena/mcp/handlers_procedural.py',
        'src/athena/mcp/handlers_prospective.py',
        'src/athena/mcp/handlers_consolidation.py',
        'src/athena/mcp/handlers_episodic.py',
        'src/athena/mcp/handlers_graph.py',
    ]

    total_conversions = 0
    all_conversions = []

    print("\n" + "="*70)
    print("COMPREHENSIVE TOON CONVERSION - All Remaining Handlers")
    print("="*70 + "\n")

    for filepath_str in files_to_convert:
        filepath = Path(filepath_str)
        if not filepath.exists():
            print(f"âŠ˜ {filepath_str} not found")
            continue

        count, convs = convert_file_toon(filepath)
        if count > 0:
            total_conversions += count
            all_conversions.extend(convs)
            print(f"âœ… {filepath.name}: {count} handlers converted")

    # Verify all files compile
    print("\n" + "="*70)
    print("SYNTAX VERIFICATION")
    print("="*70 + "\n")

    import subprocess
    all_valid = True

    for filepath_str in files_to_convert:
        filepath = Path(filepath_str)
        if not filepath.exists():
            continue

        result = subprocess.run(
            ["python", "-m", "py_compile", str(filepath)],
            capture_output=True,
            text=True
        )

        if result.returncode == 0:
            print(f"âœ… {filepath.name}")
        else:
            print(f"âŒ {filepath.name}: {result.stderr[:100]}")
            all_valid = False

    print("\n" + "="*70)
    print(f"FINAL RESULTS")
    print("="*70)
    print(f"Total handlers converted: {total_conversions}")
    print(f"All files valid: {'âœ… Yes' if all_valid else 'âŒ No'}")
    print("="*70 + "\n")

    # Estimate impact
    if total_conversions > 0:
        tokens_per_handler = 200
        compression_ratio = 0.57
        tokens_saved_per = int(tokens_per_handler * compression_ratio)
        total_saved = total_conversions * tokens_saved_per

        alignment_improvement = (total_conversions / 7) * 0.5  # ~0.5% per 7 handlers

        print(f"ðŸ“Š ESTIMATED IMPACT:")
        print(f"   - Tokens saved per handler: ~{tokens_saved_per}")
        print(f"   - Total tokens saved: ~{total_saved:,}")
        print(f"   - Alignment improvement: +{alignment_improvement:.1f}%")
        print()

    return 0 if all_valid else 1

if __name__ == "__main__":
    exit(main())
