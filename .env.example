# Athena Phase 5 PostgreSQL Configuration
# Copy this to .env and configure for your environment

# ============================================================================
# DATABASE BACKEND SELECTION
# ============================================================================

# Which database backend to use: sqlite or postgres
# If not set, will auto-detect based on ATHENA_POSTGRES_HOST
# ATHENA_DB_TYPE=postgres

# ============================================================================
# POSTGRESQL CONFIGURATION
# ============================================================================

# PostgreSQL server host
ATHENA_POSTGRES_HOST=localhost

# PostgreSQL server port
ATHENA_POSTGRES_PORT=5432

# PostgreSQL database name
ATHENA_POSTGRES_DBNAME=athena

# PostgreSQL user
ATHENA_POSTGRES_USER=athena

# PostgreSQL password
ATHENA_POSTGRES_PASSWORD=athena_dev

# Connection pool minimum size
ATHENA_POSTGRES_MIN_SIZE=2

# Connection pool maximum size (adjust for concurrency)
ATHENA_POSTGRES_MAX_SIZE=10

# ============================================================================
# SQLITE CONFIGURATION (Phase 4 Fallback)
# ============================================================================

# Path to SQLite database file (only used if ATHENA_DB_TYPE=sqlite)
# ATHENA_DB_PATH=~/.athena/memory.db

# ============================================================================
# EMBEDDINGS CONFIGURATION
# ============================================================================

# Embedding provider: ollama, anthropic, mock
# EMBEDDING_PROVIDER=ollama

# Ollama host (if using ollama)
# OLLAMA_HOST=http://localhost:11434

# Anthropic API key (if using anthropic embeddings)
# ANTHROPIC_API_KEY=sk-xxx

# ============================================================================
# LLAMA.CPP CONFIGURATION
# ============================================================================

# llama.cpp server host for local embeddings
# LLAMACPP_HOST=localhost

# llama.cpp server port
# LLAMACPP_PORT=8000

# llama.cpp embedding model dimension
# LLAMACPP_EMBEDDING_DIM=768

# ============================================================================
# LOGGING CONFIGURATION
# ============================================================================

# Debug logging
# DEBUG=1

# Log level: DEBUG, INFO, WARNING, ERROR
# LOG_LEVEL=INFO

# ============================================================================
# VECTOR SEARCH CONFIGURATION
# ============================================================================

# Vector similarity threshold for search (0-1)
VECTOR_SIMILARITY_THRESHOLD=0.3

# IVFFlat index lists (number of lists for clustering)
VECTOR_INDEX_LISTS=100

# IVFFlat probes (higher = more accurate but slower)
VECTOR_INDEX_PROBES=20

# ============================================================================
# CONSOLIDATION CONFIGURATION
# ============================================================================

# Consolidation window in seconds (when to run consolidation)
CONSOLIDATION_INTERVAL=3600

# Reconsolidation window in minutes (labile memory window)
RECONSOLIDATION_WINDOW_MINUTES=60

# ============================================================================
# PERFORMANCE CONFIGURATION
# ============================================================================

# Target read latency (ms) for monitoring
TARGET_READ_LATENCY_MS=100

# Target write latency (ms) for monitoring
TARGET_WRITE_LATENCY_MS=300

# Enable query performance monitoring
ENABLE_PERFORMANCE_MONITORING=true
