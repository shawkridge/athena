---
name: hypothesis-validation
description: |
  When you need to test assumptions, verify claims, or identify weaknesses in proposals.
  When assessing risk, validating logical soundness, or stress-testing ideas.
  When critical thinking is needed to identify what could go wrong and how likely it is.
---

# Hypothesis Validation Skill

Validation specialist for testing assumptions, verifying claims, and identifying weaknesses through rigorous analysis.

## When to Use

- Need to verify assumptions before committing
- Testing claims for logical soundness
- Identifying potential weaknesses in proposals
- Risk assessment and stress testing
- Checking evidence quality
- Finding alternative explanations
- Critical evaluation needed

## Validation Framework

### 1. Assumption Analysis
For each claim, identify:
- **Explicit Assumptions** - Stated assumptions
- **Implicit Assumptions** - Unstated assumptions
- **Questionable Assumptions** - Which are weak?
- **Critical Assumptions** - Which would invalidate claim if false?

### 2. Evidence Quality
Assess:
- **Source Credibility** - How reliable?
- **Evidence Type** - Empirical data, logical deduction, expert opinion?
- **Sample Size** - Sufficient data?
- **Applicability** - Relevant to your context?

### 3. Logical Soundness
Check:
- **Logical Flow** - Does it follow?
- **Causation vs Correlation** - Proven or assumed?
- **Scope Creep** - Does conclusion exceed evidence?
- **Alternative Explanations** - Are other explanations possible?

### 4. Risk Assessment
Identify:
- **What Could Go Wrong** - Failure modes
- **Impact If Wrong** - Severity of error
- **Likelihood** - How probable?
- **Mitigation** - How to prevent?

## Testing Process

1. **Claim Extraction** - What exactly is being claimed?
2. **Assumption Identification** - What must be true?
3. **Evidence Review** - What supports this?
4. **Weakness Identification** - Where could it fail?
5. **Risk Assessment** - What's the danger?

## Output Format

```
Hypothesis Testing & Validation
Claim: [main claim being tested]
Context: [where this applies]

Assumptions Identified:
- [Assumption 1] - Credibility: [High/Medium/Low]
- [Assumption 2] - Credibility: [High/Medium/Low]

Evidence Quality:
- [Evidence 1] - Type: [empirical/logical/expert], Credibility: [score]
- [Evidence 2] - Type: [empirical/logical/expert], Credibility: [score]

Logical Analysis:
- Argument Structure: [valid/flawed]
- Causation Established: [yes/assumed/unclear]
- Scope: [appropriate/overstated/understated]

Weaknesses Identified:
1. [Weakness 1] - Impact: [if this fails, then...]
2. [Weakness 2] - Impact: [if this fails, then...]

Risk Assessment:
- Risk Level: [High/Medium/Low]
- Primary Risks: [list]
- Likelihood: [probability estimate]
- Potential Impact: [consequences if wrong]

Stress Tests:
- Extreme Scenario A: [what happens at limit]
- Extreme Scenario B: [what happens at limit]

Recommendations:
- [Mitigation 1]
- [Mitigation 2]
- [Further validation needed]

Confidence Assessment:
- Overall Confidence: [percentage]
- What Would Increase Confidence: [factors]
- Critical Unknowns: [what's still unclear]
```

## Example Use Cases

### Architecture Decision Validation
"Should we adopt microservices?"
→ Tests assumptions (team expertise, scale needs), identifies risks (complexity, coordination), assesses evidence quality

### Technical Claim Verification
"GraphRAG improves retrieval by 30%"
→ Checks evidence (sample size, context), identifies assumptions (query types), finds alternative explanations

### Proposal Stress Testing
"New consolidation strategy will improve quality"
→ Identifies failure modes, tests edge cases, assesses risk/reward, recommends mitigations

Use hypothesis validation for rigorous critical analysis before committing to decisions.
