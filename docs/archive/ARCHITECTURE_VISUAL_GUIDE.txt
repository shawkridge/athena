ATHENA ARCHITECTURE VISUAL REFERENCE GUIDE
===========================================

================================================================================
SECTION 1: TOOL SYSTEM ARCHITECTURE (Fragmented - Two Systems)
================================================================================

SYSTEM A: ACTIVE (handlers.py - 11,348 LOC)
┌────────────────────────────────────────────────────────────────────────────┐
│                     MemoryMCPServer.__init__()                             │
├────────────────────────────────────────────────────────────────────────────┤
│  ↓ _register_tools()                                                        │
│  ├─ list_tools() → Tool[]                                                  │
│  │  ├─ memory_tools        (27 operations)                                 │
│  │  ├─ episodic_tools      (10 operations)                                 │
│  │  ├─ graph_tools         (15 operations)                                 │
│  │  ├─ planning_tools      (16 operations)                                 │
│  │  ├─ task_management_tools                                               │
│  │  └─ ... 6 more meta-tools                                               │
│  │                                                                          │
│  └─ call_tool(name, args)                                                  │
│     ├─ Rate check                                                          │
│     ├─ router = OperationRouter(self)  ← RE-INITIALIZED EVERY CALL!       │
│     └─ router.route(meta_tool, operation)                                  │
│        └─ getattr(self, "_handle_" + operation)  ← 332 methods             │
│           ├─ _handle_recall()                                              │
│           ├─ _handle_remember()                                            │
│           ├─ _handle_record_event()                                        │
│           └─ ... 329 more                                                  │
│                                                                             │
│  Token Cost: 15K tokens (85% reduction from 120+ individual tools)         │
└────────────────────────────────────────────────────────────────────────────┘


SYSTEM B: UNUSED (tools/*.py - Modular, NOT integrated)
┌────────────────────────────────────────────────────────────────────────────┐
│                        ToolManager                                          │
│                    initialize_tools()                                      │
├────────────────────────────────────────────────────────────────────────────┤
│  ↓ Registry                                                                 │
│  ├─ RecallTool(BaseTool)      ← Async execute(**params)                   │
│  ├─ RememberTool(BaseTool)                                                │
│  ├─ ForgetTool(BaseTool)                                                  │
│  ├─ OptimizeTool(BaseTool)                                                │
│  ├─ SystemHealthCheckTool(BaseTool)                                       │
│  └─ ... more tools                                                         │
│                                                                             │
│  ToolRegistry.register(tool) → Dict[str, BaseTool]                         │
│  ToolRegistry.get(name) → Optional[BaseTool]                               │
│                                                                             │
│  STATUS: ✗ NOT used by call_tool()                                        │
│          ✗ NOT listed in list_tools()                                      │
│          ✓ Properly structured with metadata                              │
│          ✓ Async/await support                                             │
│          ✓ Composable results (ToolResult dataclass)                      │
└────────────────────────────────────────────────────────────────────────────┘

INTEGRATION STATUS: TWO PARALLEL SYSTEMS (FRAGMENTED)
  System A (active) and System B (unused) don't communicate
  Expected: System B should replace System A


================================================================================
SECTION 2: DATA FLOW: AGENT REQUEST → RESPONSE
================================================================================

Request Path (Agent to Response):
┌─────────────┐
│ Agent       │ "Recall memories about Phase 1"
└──────┬──────┘
       │ MCP Tool Call
       ├─ name: "memory_tools"
       ├─ operation: "recall"
       └─ query: "Phase 1"
       │
       ▼
┌──────────────────────────────┐
│ MemoryMCPServer.call_tool()  │
│ (handlers.py:1184)           │
└──────┬───────────────────────┘
       │ Check Rate Limit
       ├─ Read limit: 100/min ✓
       │
       ▼
┌──────────────────────────────┐
│ OperationRouter.route()      │
│ ("memory_tools", "recall")   │
└──────┬───────────────────────┘
       │ Dispatch
       ├─ method = "_handle_recall"
       │
       ▼
┌──────────────────────────────┐
│ _handle_recall(args)         │
│ (handlers.py:1252)           │
└──────┬───────────────────────┘
       │ Validate args
       ├─ project = require_project()
       ├─ memory_types = parse(args)
       │
       ▼
┌──────────────────────────────────┐
│ UnifiedMemoryManager.retrieve()  │
│ (manager.py:124)                 │
└──────┬───────────────────────────┘
       │ Query Type Classification
       ├─ Contains "Phase 1" → PLANNING type
       │
       ▼ (Route to Planning Layer)
┌──────────────────────────────────┐
│ _query_planning()                │
│ (manager.py:485)                 │
└──────┬───────────────────────────┘
       │ Memory Search
       ├─ semantic_store.search(query, k=5)
       │
       ▼
┌──────────────────────────────────┐
│ Results (MemoryVector[])         │
└──────┬───────────────────────────┘
       │ Apply Confidence Scores
       ├─ confidence_scorer.score(result)
       │
       ▼
┌──────────────────────────────────┐
│ Response Dict                    │
└──────┬───────────────────────────┘
       │ Format as JSON
       ├─ json.dumps(result, indent=2)
       │
       ▼
┌──────────────────────────────────┐
│ TextContent                      │
│ (type="text", text=json_string)  │
└──────┬───────────────────────────┘
       │
       ▼
┌─────────────┐
│ Agent       │ Receives formatted text response
└─────────────┘

Total Operations: 8
Potential Bottlenecks:
  ✗ OperationRouter re-initialized (handlers.py:1198)
  ✗ Query type classification (lexical, not semantic)
  ✗ json.dumps(indent=2) formatting (adds 20-30% padding)
  ✗ NO pagination (all results in one response)


================================================================================
SECTION 3: QUERY CLASSIFICATION ROUTING
================================================================================

Input: "When was Phase 4 Week 1 completed?"

┌─────────────────────────────────────────────────────────────────┐
│ manager.py:_classify_query(query)                              │
├─────────────────────────────────────────────────────────────────┤
│  Step 1: Lower-case input                                       │
│  "when was phase 4 week 1 completed?"                          │
│                                                                  │
│  Step 2: Keyword matching (8 types checked in order)           │
│  ├─ Temporal? Contains "when" → YES ✓                          │
│  ├─ Relational? Contains "depends", "related", etc. → NO       │
│  ├─ Planning? Contains "plan", "decompose", etc. → NO          │
│  ├─ Procedural? Contains "how to", "workflow", etc. → NO       │
│  ├─ Prospective? Contains "task", "todo", "remind", etc. → NO  │
│  ├─ Factual? Contains "what is", "who is", etc. → NO           │
│  └─ Meta? Contains "know about", "quality", etc. → NO          │
│                                                                  │
│  Step 3: Return first match                                     │
│  └─ QueryType.TEMPORAL                                          │
│                                                                  │
└─────────────────────────────────────────────────────────────────┘

Route Decision:
┌──────────────────────────────────────────────────────────────────┐
│ if query_type == QueryType.TEMPORAL:                             │
│     results["episodic"] = self._query_episodic(...)             │
│     # Search episodic_store for events matching "Phase 4"       │
│                                                                   │
│ Returns: {                                                        │
│     "episodic": [                                                │
│         {                                                         │
│             "event": "Phase 4 Week 1 completed",                │
│             "timestamp": "2025-11-11T...",                      │
│             "relevance": 0.98,                                  │
│             "confidence": 0.95                                  │
│         }                                                         │
│     ]                                                             │
│ }                                                                 │
└──────────────────────────────────────────────────────────────────┘

LIMITATION: Purely Lexical Classification
  Input: "In what timeframe did Phase 1 milestone X depend on Phase 0 work?"
  Detected: TEMPORAL (contains "timeframe")
  Correct: RELATIONAL (contains "depend on")
  Result: Wrong layer searched, missing dependency info


================================================================================
SECTION 4: MEMORY LAYER STACK (8 Layers)
================================================================================

Layer 8 (Thinking/Support)
┌─────────────────────────────────────────────────────────────────┐
│ RAG Manager, Planning (validator, formal_verification), Research│
│ Learning (decision extraction), Execution (monitoring)           │
└────────────────┬────────────────────────────────────────────────┘
                 │
Layer 7 (Consolidation - Sleep-like Pattern Extraction)
┌────────────────────────────────────────────────────────────────┐
│ ConsolidationSystem                                             │
│  ├─ Statistical clustering (System 1, ~100ms)                  │
│  ├─ Heuristic pattern extraction                               │
│  └─ LLM validation when uncertainty > 0.5 (System 2)           │
│  Result: Episodic events → Semantic patterns/knowledge         │
└────────────────┬────────────────────────────────────────────────┘
                 │
Layer 6 (Meta-Memory - Knowledge About Knowledge)
┌────────────────────────────────────────────────────────────────┐
│ MetaMemoryStore                                                │
│  ├─ Quality metrics (compression, recall, consistency)         │
│  ├─ Expertise tracking (domain knowledge)                      │
│  ├─ Attention salience (focus management)                      │
│  └─ Cognitive load (Baddeley 7±2)                              │
└────────────────┬────────────────────────────────────────────────┘
                 │
Layer 5 (Knowledge Graph - Semantic Structure)
┌────────────────────────────────────────────────────────────────┐
│ GraphStore                                                      │
│  ├─ Entities (Project, Phase, File, Function, etc.)           │
│  ├─ Relations (contains, depends_on, implements, etc.)        │
│  ├─ Communities (Leiden algorithm)                             │
│  └─ Observations (contextual notes)                            │
└────────────────┬────────────────────────────────────────────────┘
                 │
Layer 4 (Prospective Memory - Goals & Tasks)
┌────────────────────────────────────────────────────────────────┐
│ ProspectiveStore                                               │
│  ├─ Tasks (with status, priority, deadline)                   │
│  ├─ Goals (with hierarchy)                                     │
│  ├─ Triggers (time/event/file-based)                          │
│  └─ Monitoring (task progress, blockers)                       │
└────────────────┬────────────────────────────────────────────────┘
                 │
Layer 3 (Procedural Memory - Workflows & Patterns)
┌────────────────────────────────────────────────────────────────┐
│ ProceduralStore                                                │
│  ├─ Procedures (extracted workflows)                           │
│  ├─ Pattern extraction (from episodic events)                  │
│  ├─ Effectiveness tracking                                     │
│  └─ Pattern matching                                           │
└────────────────┬────────────────────────────────────────────────┘
                 │
Layer 2 (Semantic Memory - Knowledge Representation)
┌────────────────────────────────────────────────────────────────┐
│ MemoryStore (Semantic)                                         │
│  ├─ Vector embeddings (Ollama or Anthropic)                    │
│  ├─ BM25 full-text index                                       │
│  ├─ Hybrid search (semantic + lexical)                         │
│  └─ Memory types: fact, pattern, decision, context             │
└────────────────┬────────────────────────────────────────────────┘
                 │
Layer 1 (Episodic Memory - Event Sequence)
┌────────────────────────────────────────────────────────────────┐
│ EpisodicStore (with Spatial/Temporal Grounding)                │
│  ├─ Events with timestamps (when)                              │
│  ├─ Spatial context (file paths, locations)                    │
│  ├─ Session tracking (code sessions, work sessions)            │
│  ├─ Temporal chains (causality)                                │
│  └─ Event types: action, decision, error, test_run, etc.      │
└────────────────┬────────────────────────────────────────────────┘
                 │
                 ▼
┌────────────────────────────────────────────────────────────────┐
│ Database (SQLite local or PostgreSQL Docker)                   │
└────────────────────────────────────────────────────────────────┘

Query Routing Examples:
  "What is X?" → Layer 2 (Semantic)
  "When was X completed?" → Layer 1 (Episodic)
  "What depends on X?" → Layer 5 (Knowledge Graph)
  "How to do X?" → Layer 3 (Procedural)
  "Remind me about X" → Layer 4 (Prospective)
  "What's the quality of Layer Y?" → Layer 6 (Meta-Memory)


================================================================================
SECTION 5: TOKEN OPTIMIZATION STRATEGIES
================================================================================

Tool Definition Token Cost:
  BEFORE (120+ individual tools):
    Tool: recall
    Tool: remember
    ... 118 more
    ≈ 105K tokens
  
  AFTER (11 meta-tools with operation routing):
    Tool: memory_tools with operation enum (27 items)
    Tool: episodic_tools with operation enum (10 items)
    ... 9 more meta-tools
    ≈ 15K tokens
  
  REDUCTION: 90K tokens (85%)
  COST: ~1ms operation routing overhead per call


Response Optimization (MISSING):
  Current: json.dumps(result, indent=2)
  └─ Adds 20-30% padding for readability
  
  Potential: json.dumps(result, separators=(',', ':'))
  └─ Compact format, harder to read, 20-30% smaller


Storage Optimization (PRESENT):
  Strategy 1: Temporal Decay
    - Old memories compressed by age
    - Recent memories kept at full fidelity
  
  Strategy 2: Importance Weighting
    - Select top-k memories by usefulness
    - Budget tokens per query
    - Default: 2000 tokens
  
  Strategy 3: Consolidation Compression
    - Cluster similar events
    - Extract patterns
    - Discard noisy details
  
  Result: Memory database stays small (<10 MB typical)


Working Memory Optimization:
  Baddeley's Model (7±2 items)
    - CentralExecutive: Task management
    - PhonologicalLoop: Verbal working memory
    - VisuospatialSketchpad: Visual working memory
    - EpisodicBuffer: Integration
  
  Effect: Only high-priority items stay in focus
  Benefit: Prevents context window overflow


Caching Strategy:
  LRU Cache (1000 items)
    - Stores semantic search results
    - NOT cleared between requests
    - Helps with repeated queries


BOTTLENECKS:
  ✗ json.dumps(indent=2) padding (20-30%)
  ✗ OperationRouter re-initialization per call
  ✗ Query classification with no caching
  ✗ Full schema in list_tools() recalculated every request
  ✗ NO result pagination (all results in one response)


================================================================================
SECTION 6: SECURITY & SAFETY ARCHITECTURE
================================================================================

Three-Tier Safety System:

Tier 1: RATE LIMITING (mcp/rate_limiter.py)
┌────────────────────────────────────────────────────────────────┐
│ Token Bucket Algorithm                                         │
│ Limits per request type:                                       │
│  ├─ Read operations: 100/min (max burst: 20)                  │
│  ├─ Write operations: 30/min (max burst: 6)                   │
│  ├─ Admin operations: 10/min (max burst: 2)                   │
│                                                                 │
│ Checked BEFORE every tool call (handlers.py:1191)              │
│ └─ if not self.rate_limiter.allow_request(name):              │
│      return rate_limit_response()                              │
│                                                                 │
│ Prevents: DoS, token exhaustion                                │
└────────────────────────────────────────────────────────────────┘

Tier 2: SAFETY EVALUATION (safety/evaluator.py)
┌────────────────────────────────────────────────────────────────┐
│ evaluate_change(project_id, change_type, confidence_score)   │
│                                                                │
│ Risk Assessment:                                               │
│  Input: confidence_score (0.0 - 1.0)                           │
│  ├─ 0.0 - 0.3:   CRITICAL (auto_reject)                       │
│  ├─ 0.3 - 0.6:   HIGH (require_approval)                      │
│  ├─ 0.6 - 0.8:   MEDIUM (auto_approve with logging)           │
│  └─ 0.8 - 1.0:   LOW (auto_approve)                           │
│                                                                │
│ Policy-Based Decision:                                         │
│  ├─ Change type (database_write, code_delete, etc.)          │
│  ├─ Risk level assessment                                      │
│  ├─ Number of affected files                                  │
│  └─ Agent confidence score                                    │
│                                                                │
│ Output:                                                        │
│  {                                                             │
│    "decision": "auto_approve" | "require_approval" | ...     │
│    "risk_level": "low" | "medium" | "high" | "critical",    │
│    "reason": "explanation"                                    │
│  }                                                             │
│                                                                │
│ Prevents: Unsafe changes, data loss, security breaches       │
└────────────────────────────────────────────────────────────────┘

Tier 3: ASSUMPTION VALIDATION (execution/validator.py)
┌────────────────────────────────────────────────────────────────┐
│ register_assumption(id, description, expected_value, method)  │
│ check_assumption(id, actual_value)                            │
│                                                                │
│ During execution:                                              │
│  ├─ Register expected conditions                               │
│  ├─ Periodically check assumptions                            │
│  ├─ Track violations with severity                            │
│  └─ Trigger replanning on deviation                          │
│                                                                │
│ Example:                                                       │
│  register_assumption(                                          │
│    "file_exists",                                             │
│    "source file must exist",                                  │
│    expected_value=True,                                       │
│    check_frequency=timedelta(seconds=5)                       │
│  )                                                             │
│                                                                │
│ Prevents: Invalid assumptions in plans                        │
└────────────────────────────────────────────────────────────────┘


Input Validation:
┌────────────────────────────────────────────────────────────────┐
│ MINIMAL: args dict used directly without validation            │
│                                                                │
│ Current (handlers.py:1239):                                   │
│  memory_id = await self.store.remember(                       │
│    content=args["content"],  ← NO length check               │
│    memory_type=MemoryType(args["memory_type"]),  ← Enum only  │
│    project_id=project.id,                                     │
│    tags=args.get("tags", [])  ← NO validation                │
│  )                                                             │
│                                                                │
│ RISKS:                                                         │
│  ✗ Missing required parameters → KeyError                     │
│  ✗ Invalid content size → Memory/performance issues           │
│  ✗ No type checking → Conversion errors                       │
│  ✗ No SQL injection prevention (but parameterized queries)   │
│                                                                │
│ Mitigation:                                                    │
│  ✓ Parameterized database queries (prevents SQL injection)    │
│  ✓ Enum validation for memory types                           │
│  ✓ Project-level access scoping                               │
└────────────────────────────────────────────────────────────────┘


Sandbox Execution (sandbox/execution_context.py):
┌────────────────────────────────────────────────────────────────┐
│ ExecutionContext - MONITORING ONLY (NOT ISOLATION)             │
│                                                                │
│ Capabilities:                                                  │
│  ✓ Captures stdout/stderr via sys.stdout/stderr wrapping      │
│  ✓ Tracks resource usage (memory, CPU, duration)              │
│  ✓ Records execution timeline (events)                        │
│  ✓ Detects violations (file access, network attempts)        │
│                                                                │
│ Limitations:                                                   │
│  ✗ NOT subprocess isolation (runs in same process)            │
│  ✗ NOT restricted filesystem (can access all files)           │
│  ✗ NOT network isolation (can make network calls)             │
│  ✗ Can MONITOR but CANNOT PREVENT violations                  │
│                                                                │
│ Why Safe by Design:                                            │
│  Agents can ONLY call MCP tools, not execute code directly    │
│  └─ Tool-calling model prevents code execution                │
│  └─ No dynamic code synthesis or execution                    │
│  └─ All agent operations routed through memory layer          │
└────────────────────────────────────────────────────────────────┘


Access Control:
┌────────────────────────────────────────────────────────────────┐
│ Project-Level Isolation (SINGLE-USER SYSTEM)                   │
│                                                                │
│ All queries scoped to project_id:                              │
│  project = self.project_manager.require_project()             │
│  results = self.store.recall(                                 │
│    query=query,                                               │
│    project_id=project.id,  ← Always enforced                  │
│    k=k                                                         │
│  )                                                             │
│                                                                │
│ NO user-level access control:                                 │
│  ✗ Single user assumption                                     │
│  ✗ No role-based access control (RBAC)                        │
│  ✗ No permission checks                                       │
│  ✗ No audit trails (per-user)                                │
│                                                                │
│ For multi-user: Would need:                                   │
│  - User authentication                                        │
│  - Per-operation permission checks                            │
│  - Audit logging by user                                      │
│  - Row-level security in database                            │
└────────────────────────────────────────────────────────────────┘


================================================================================
SECTION 7: CRITICAL ISSUES & RECOMMENDATIONS
================================================================================

1. TOOL SYSTEM FRAGMENTATION
   Severity: HIGH
   Location: handlers.py vs tools/*.py
   Impact: Tool discovery unclear, two competing systems
   Code: handlers.py creates ToolManager but never uses it
   Fix: 
    Step 1: Migrate all 332 _handle_* methods to modular tools
    Step 2: Connect ToolRegistry to MCP list_tools()
    Step 3: Remove old handler methods
   Effort: 3-4 days
   Value: Cleaner architecture, better maintainability


2. NO RESULT PAGINATION
   Severity: MEDIUM
   Location: All handlers (1301+)
   Impact: Large result sets overflow context window
   Example: _handle_list_memories returns ALL memories
   Fix:
    Step 1: Add k parameter to all handlers
    Step 2: Add max limit enforcement (k=5 default, max=100)
    Step 3: Add offset parameter for true pagination
   Effort: 1-2 days
   Value: Prevents context overflow, enables large datasets


3. QUERY CLASSIFICATION PURELY LEXICAL
   Severity: MEDIUM
   Location: manager.py:266-299
   Impact: Misroutes complex queries, no semantic understanding
   Example: "What depends on X?" routed to TEMPORAL (wrong)
   Fix:
    Step 1: Fine-tune BERT for query intent classification
    Step 2: Cache classification results
    Step 3: Fall back to lexical on uncertainty
   Effort: 2-3 days
   Value: Better routing accuracy, improved results


4. NO STRUCTURED RESULTS
   Severity: MEDIUM
   Location: All handlers return TextContent
   Impact: Tool composition impossible, tool chaining blocked
   Fix:
    Step 1: Create StructuredResult dataclass
    Step 2: Update all handlers to return StructuredResult
    Step 3: Add TextContent serializer for MCP
    Step 4: Enable tool composition via result chaining
   Effort: 2-3 days
   Value: Tool composition, advanced workflows


5. NO INPUT VALIDATION
   Severity: MEDIUM
   Location: handlers.py (args used directly)
   Impact: Missing params → errors, invalid types → crashes
   Fix:
    Step 1: Create Pydantic schema per tool operation
    Step 2: Validate args in call_tool() before routing
    Step 3: Return 400 Bad Request for invalid params
   Effort: 1-2 days
   Value: Better error handling, prevent crashes


6. ROUTER RE-INITIALIZATION
   Severity: LOW
   Location: handlers.py:1198
   Impact: ~100ms overhead per tool call (estimate)
   Code: router = OperationRouter(self)  ← Every call
   Fix:
    Option A: self.router = OperationRouter(self) in __init__
    Option B: @classmethod dispatch in OperationRouter
   Effort: <1 day
   Value: 5-10% latency improvement


7. RESPONSE FORMATTING NOT OPTIMIZED
   Severity: LOW
   Location: handlers.py (json.dumps with indent=2)
   Impact: 20-30% padding overhead
   Fix:
    Option A: Use json.dumps(separators=(',', ':'))
    Option B: Add 'format' parameter to tool calls
   Effort: <1 day
   Value: 20-30% response size reduction


================================================================================
QUICK DECISION TREES
================================================================================

SHOULD I MIGRATE TO MODULAR TOOLS?
  Q1: Is tool discovery breaking?
    YES → MIGRATE NOW (high priority)
    NO → Can defer
  Q2: Do you need tool composition?
    YES → MIGRATE (required for composition)
    NO → Nice to have
  Recommendation: YES - Architecturally cleaner, enables composition


SHOULD I ADD PAGINATION?
  Q1: Are large result sets causing context overflow?
    YES → ADD NOW (critical)
    NO → Monitor
  Q2: Do you expect >10K memories in database?
    YES → ADD NOW (preemptive)
    NO → Can defer
  Recommendation: YES - Simple to add, big impact


SHOULD I IMPROVE QUERY CLASSIFICATION?
  Q1: Is query misrouting affecting results?
    YES → IMPROVE NOW
    NO → Monitor
  Q2: Do users ask complex queries (multi-clause)?
    YES → IMPROVE (needed for complex queries)
    NO → Lexical OK
  Recommendation: YES if complex queries common, NO for simple queries


SHOULD I ADD STRUCTURED RESULTS?
  Q1: Do you need tool composition?
    YES → REQUIRED
    NO → TextContent OK
  Q2: Are you building advanced workflows?
    YES → REQUIRED
    NO → Simple workflows OK
  Recommendation: YES if future features need composition, NO if not planned

